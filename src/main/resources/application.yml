server:
  port: ${random.int[10000,19999]} # 随机端口，方便启动多个消费者
#  port: 8081 # 随机端口，方便启动多个消费者
canal:
 server: 192.168.84.22:11111
 destination: example
spring:
  # Kafka 配置项，对应 KafkaProperties 配置类
  kafka:
    bootstrap-servers: 127.0.0.1:9092 # 指定 Kafka Broker 地址，可以设置多个，以逗号分隔
    # Kafka Producer 配置项
    producer:
      acks: 1 # 0-不应答。1-leader 应答。-1 或者 all 表示 leader 和 follower 应答。
      retries: 3 # 发送失败时，重试发送的次数
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 消息的 key 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # 消息的 value 的序列化
    # Kafka Consumer 配置项
    consumer:
      auto-offset-reset: earliest # 设置消费者分组最初的消费进度为 earliest。
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      enable-auto-commit: false # 使用 Spring-Kafka 的消费进度的提交机制
    # Kafka Consumer Listener 监听器配置
    listener:
      missing-topics-fatal: false # 消费监听接口监听的主题不存在时，默认会报错。所以通过设置为 false ，解决报错
      ack-mode: MANUAL # 调用时，先标记提交消费进度。等到当前消息被消费完成，然后在提交消费进度。

  # spring cloud stream kafka 配置项
  cloud:
    stream:
      default-binder: kafka           #如果还有rabbitmq的话需要制定一个默认的
#      kafka:
#        binder:
#          brokers: 127.0.0.1:9092     # kafka地址
#          zk-nodes: 127.0.0.1:2181    # zk地址 springboot2.0之后 可省略
#          auto-create-topics: true
#            # Kafka Binding 配置项，对应 KafkaBindingProperties 类
#        bindings:
#          input:
#          # Kafka Consumer 配置项，对应 KafkaConsumerProperties 类
#           consumer:
#            enable-dlq: true # 是否开启死信队列，默认为 false 关闭
#            dlq-name: stream-demo.group-1.errors # 死信队列名，默认为 `errors.{topicName}.{consumerGroup}`
#      bindings:
#        output:                       #默认output
#          destination: stream-demo    #消息发往的目的地
#          content-type: application/json    #消息发送格式
#        myOutput:                     #自定义output
#          destination: stream-demo    #消息发往的目的地
#          content-type: application/json  #消息发送格式
#          producer:
#            partitionKeyExpression: payload['id'] # 配置分区的输出绑定
#        input:                        #接收
#          destination: stream-demo
#          group: group-1
#          consumer:
#           max-attempts: 3 # 重试次数，默认为 3 次。
#           back-off-initial-interval: 3000 # 重试间隔的初始值，单位毫秒，默认为 1000
#           back-off-multiplier: 2.0 # 重试间隔的递乘系数，默认为 2.0
#           back-off-max-interval: 10000 # 重试间隔的最大值，单位毫秒，默认为 10000
#           enable-dlq: true # 是否开启死信队列，默认为 false 关闭
#           concurrency:  2 # 每个 Consumer 消费线程数的初始大小，默认为 1
#        input2:                        #接收
#          destination: stream-demo
#          group: group-2

  security:
   user:
     name: admin
     password: admin

  application:
    name: allTest
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://127.0.0.1:3306/MyTest?useSSL=false
    username: root
    password: 1111
  redis:
   host: 127.0.0.1
   port: 6379
   password:
   database: 0
   jedis:
     pool:
       max-active: 100        # 最大连接数量
       max-idle: 10           # 最大空闲数量
       min-idle: 10           # 最小空闲数量
       max-wait: 1000000000ms # 获取连接时的最大等待毫秒数
  #  rabbitmq:
#    host: localhost
#    port: 5672
#    username: guest
#    password: guest
#    virtual-host: /

  jpa:
    properties:
      hibernate:
        hbm2ddl:
          auto: update
        dialect: org.hibernate.dialect.MySQL5InnoDBDialect
        format_sql: true
    show-sql: true
logging:
 level:
  org.zhire.mapper: debug


